[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Prueba Técnica para Científico de Datos",
    "section": "",
    "text": "Prueba técnica para el rol de Científico de Datos para Naowee.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "case2_introduction.html",
    "href": "case2_introduction.html",
    "title": "Caso 2: Análisis de Desempeño Estudiantil en Matemáticas",
    "section": "",
    "text": "El reto analítico\nUna universidad ha recopilado información sobre el desempeño de sus estudiantes en matemáticas con el objetivo de identificar los factores que más influyen en su rendimiento. Se busca entender cómo aspectos como el tiempo de estudio, la asistencia a actividades extracurriculares y las horas de sueño inciden en el puntaje final.\n\n\nMetodología y enfoque\nA través del análisis de datos de estudiantes universitarios, se espera: - Evaluar la relación entre el tiempo de estudio y las calificaciones finales. - Identificar diferencias de desempeño según la asistencia a actividades extracurriculares. - Aplicar modelos de regresión para predecir el rendimiento académico y entender sus principales determinantes.\n\n\nPreguntas clave\n\n¿Cuáles son los principales factores que afectan el rendimiento en matemáticas?\n¿Existe una correlación entre el tiempo de estudio y la calificación final?\n¿Cómo varía el desempeño según la asistencia a actividades extracurriculares y la resolución de los ejercicios prácticos propuestos en el material de estudio?\n\n\n\nResultados esperados\nCon base en el dataset Student_Performance.csv realice:\n\nAnálisis de Estructuras de Datos a través de:\n\n\nVisualizaciones de datos: es importante que usted haga una descripción de los hallazgos.\nIdentifique las variables, tipo de dato y elabore un diccionario de datos con estas variables (puede hacerlo en Excel conectándose directamente al Raw).\n¿Es necesario transformar los datos para mejor entendimiento de los mismos? Si su respuesta es positiva, ¿qué tipo de transformaciones haría? Si considera necesario, realice las transformaciones para desarrollar los puntos posteriores.\n\n\nComo resultado del análisis de las estructuras de datos del punto anterior, elabore un análisis exploratorio donde identifique:\n\n\nEstadística descriptiva de las variables. Haga una descripción de los hallazgos.\n¿Existen diferencias estadísticas entre el puntaje final (Performance Index) y la asistencia a actividades extracurriculares? En la resolución se debe poder observar todo el proceso realizado para la respuesta.\nIdentifique los grupos o conglomerados de estudiantes según sus características\n\n\n\nProducto esperado\nEs necesario identificar potenciales estudiantes con bajo desempeño por lo que es importante desarrollar un producto de datos que le facilite a la institución la identificación temprana de estos casos. Para ello, le han solicitado a usted desarrollador una API con las siguientes condiciones:\n\nDebe desarrollar un modelo predictivo utilizando Machine Learning de los estudiantes con bajo rendimiento académico (defina usted como los identificaría a partir del análisis exploratorio hecho anteriormente). Nota: Para el entregable de la prueba debe entrenar un modelo de regresión y un modelo de clasificación.\nCon los modelos entrenados, elija uno el cuál debe ser ser comparado con al menos 2 modelos más para comprobar que es el más eficiente para identificar el bajo desempeño académico.\nDebe definir la métrica de desempeño utilizada para seleccionar el mejor modelo.\nDebe desarrollar una API para poder consumir el modelo entrenado. La API debe ser desarrollada en Python preferiblemente con FastAPI y dockerizada. Debe entregar el link del repositorio con la API.\n\n\nSi conoce los principios SOLID aplíquelos.\nSimule el CRUD de la API con diccionarios.\nEntregue las muestras utilizadas comprobar el funcionamiento de la API ya sea en Postman o en Swagger.\nSi no sabe usar Docker, elabore la API con un entorno virtual",
    "crumbs": [
      "Caso 2: Desempeño estudiantes de matemáticas",
      "Propuesta del caso"
    ]
  },
  {
    "objectID": "case1.html",
    "href": "case1.html",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "",
    "text": "La Copa Mundial Femenina de la FIFA ha experimentado un crecimiento exponencial desde su primera edición en 1991, atrayendo una audiencia global y consolidando el fútbol femenino como un pilar del deporte internacional. Con la evolución del torneo, ha surgido la necesidad de analizar tendencias en el desempeño de las selecciones, patrones de juego y factores que contribuyen al éxito en la competición.\n\n\n\nLa FIFA está interesada en un análisis detallado del rendimiento de los equipos en las distintas ediciones del torneo, identificando patrones en la cantidad de goles, frecuencia de victorias y desempeño a lo largo de los años. Se busca descubrir qué selecciones han dominado históricamente y cómo ha evolucionado el nivel de competitividad.\n\n\n\nA través del análisis de datos de partidos de la Copa Mundial Femenina desde 1991 hasta 2023, se espera: - Identificar tendencias de goles y resultados a lo largo de los torneos. - Determinar los equipos con mayor rendimiento en cada edición. - Explorar patrones de juego y evolución del fútbol femenino a nivel internacional.\n\n\n\n\n¿Cómo ha cambiado el promedio de goles por partido a lo largo de los torneos?\n¿Cuáles son las selecciones con mejor desempeño en términos de victorias?\n¿Existen tendencias en los equipos dominantes y con peor desempeño?\n\n\n\n\nPara la solución del caso, debe utilizar los siguientes dataset: world_cup_women.csv y world_cup_matches.csv",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#contexto-y-desafío",
    "href": "case1.html#contexto-y-desafío",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "",
    "text": "La Copa Mundial Femenina de la FIFA ha experimentado un crecimiento exponencial desde su primera edición en 1991, atrayendo una audiencia global y consolidando el fútbol femenino como un pilar del deporte internacional. Con la evolución del torneo, ha surgido la necesidad de analizar tendencias en el desempeño de las selecciones, patrones de juego y factores que contribuyen al éxito en la competición.",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#el-reto-analítico",
    "href": "case1.html#el-reto-analítico",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "",
    "text": "La FIFA está interesada en un análisis detallado del rendimiento de los equipos en las distintas ediciones del torneo, identificando patrones en la cantidad de goles, frecuencia de victorias y desempeño a lo largo de los años. Se busca descubrir qué selecciones han dominado históricamente y cómo ha evolucionado el nivel de competitividad.",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#metodología-y-enfoque",
    "href": "case1.html#metodología-y-enfoque",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "",
    "text": "A través del análisis de datos de partidos de la Copa Mundial Femenina desde 1991 hasta 2023, se espera: - Identificar tendencias de goles y resultados a lo largo de los torneos. - Determinar los equipos con mayor rendimiento en cada edición. - Explorar patrones de juego y evolución del fútbol femenino a nivel internacional.",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#preguntas-clave",
    "href": "case1.html#preguntas-clave",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "",
    "text": "¿Cómo ha cambiado el promedio de goles por partido a lo largo de los torneos?\n¿Cuáles son las selecciones con mejor desempeño en términos de victorias?\n¿Existen tendencias en los equipos dominantes y con peor desempeño?",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#datos",
    "href": "case1.html#datos",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "",
    "text": "Para la solución del caso, debe utilizar los siguientes dataset: world_cup_women.csv y world_cup_matches.csv",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#datos-y-utilidades",
    "href": "case1.html#datos-y-utilidades",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "0. Datos y utilidades",
    "text": "0. Datos y utilidades\n\nimport ast\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nurl_wc = \"https://raw.githubusercontent.com/daramireh/simonBolivarCienciaDatos/refs/heads/main/world_cup_women.csv\"\nurl_matches = \"https://raw.githubusercontent.com/daramireh/simonBolivarCienciaDatos/refs/heads/main/matches_1991_2023.csv\"\n\nworld_cup = pd.read_csv(url_wc)\nmatches = pd.read_csv(url_matches)\n\n\nServicio para análisis de variables\n\n\nCódigo\nclass AnalysisService:\n    def __init__(self, df: pd.DataFrame):\n        self.df = df\n\n    def summary(self) -&gt; pd.DataFrame:\n        summary_df = pd.DataFrame(\n            {\n                \"Column\": self.df.columns,\n                \"# Rows\": [self.df.shape[0] for _ in self.df.columns],\n                \"# Nulls\": [self.df[col].isna().sum() for col in self.df.columns],\n                \"Type\": [self.df[col].dtype for col in self.df.columns],\n            }\n        )\n\n        duplicated_rows = self.df.duplicated().sum()\n\n        print(f\"\\n{duplicated_rows} duplicated rows\")\n        print(summary_df)\n\n    @staticmethod\n    def related_columns(df1: pd.DataFrame, df2: pd.DataFrame) -&gt; pd.DataFrame:\n        common_columns = set(df1.columns) & set(df2.columns)\n        validation = []\n\n        for col in common_columns:\n            only_in_df1 = set(df1[col].dropna()) - set(df2[col].dropna())\n            only_in_df2 = set(df2[col].dropna()) - set(df1[col].dropna())\n\n            validation.append(\n                {\n                    \"column\": col,\n                    \"df1_nulls\": df1[col].isna().sum(),\n                    \"df2_nulls\": df2[col].isna().sum(),\n                    \"only_df1\": len(only_in_df1),\n                    \"only_df2\": len(only_in_df2),\n                }\n            )\n\n        val_df = pd.DataFrame(validation)\n\n        print(f\"\\nCommon columns: {common_columns}\\n\")\n        print(val_df)\n\n\n\n\nServicio para análisis de resultados\n\n\nCódigo\nclass ResultsService:\n    def __init__(self, data: pd.DataFrame):\n        self.data = data\n        self.base_matches = self._build_base_matches()\n        self.matches = self._build_results_matches()\n\n    @staticmethod\n    def _parse_events(x) -&gt; list:\n        if pd.isna(x) or isinstance(x, list):\n            return x if isinstance(x, list) else []\n        if isinstance(x, str):\n            try:\n                parsed = ast.literal_eval(x)\n                return parsed if isinstance(parsed, list) else []\n            except (ValueError, SyntaxError):\n                return []\n        return []\n\n    @staticmethod\n    def _count_events(x) -&gt; int:\n        return len(ResultsService._parse_events(x))\n\n    @staticmethod\n    def _parse_penalty_goals(x) -&gt; list:\n        if pd.isna(x) or not isinstance(x, str):\n            return []\n        return [\n            event.split(\"·\")[0].replace(\"(P)\", \"\").strip() for event in x.split(\"|\")\n        ]\n\n    def _explode_events(self, df, event_col, team_col, parser):\n        return (\n            df[[event_col, team_col]]\n            .dropna()\n            .assign(player=lambda x: x[event_col].apply(parser))\n            .explode(\"player\")\n            .drop(columns=event_col)\n            .dropna()\n            .rename(columns={team_col: \"team\"})\n        )\n\n    def _count_goal_assists(self, df, goal_col, team_col):\n        return (\n            df[[goal_col, team_col, \"Year\", \"Host\"]]\n            .dropna(subset=[goal_col])\n            .assign(events=lambda x: x[goal_col].apply(self._parse_events))\n            .explode(\"events\")\n            .assign(has_assist=lambda x: x[\"events\"].str.contains(\"Assist:\"))\n            .rename(columns={team_col: \"team\"})\n            .groupby([\"Year\", \"Host\", \"team\"])[\"has_assist\"]\n            .sum()\n            .reset_index(name=\"assists\")\n        )\n\n    def _build_base_matches(self) -&gt; pd.DataFrame:\n        cols_home = [\n            \"Year\",\n            \"Host\",\n            \"Attendance\",\n            \"home_team\",\n            \"home_score\",\n            \"away_score\",\n            \"home_yellow_card_long\",\n            \"home_red_card\",\n        ]\n        cols_away = [\n            \"Year\",\n            \"Host\",\n            \"Attendance\",\n            \"away_team\",\n            \"away_score\",\n            \"home_score\",\n            \"away_yellow_card_long\",\n            \"away_red_card\",\n        ]\n        cols_final = [\n            \"Year\",\n            \"Host\",\n            \"Attendance\",\n            \"team\",\n            \"goals_for\",\n            \"goals_against\",\n            \"yellow_cards\",\n            \"red_cards\",\n        ]\n\n        home = self.data[cols_home].copy()\n        home.columns = cols_final\n\n        away = self.data[cols_away].copy()\n        away.columns = cols_final\n\n        return pd.concat([home, away], ignore_index=True)\n\n    def _build_results_matches(self) -&gt; pd.DataFrame:\n        df = self.base_matches.copy()\n        df[\"yellow_cards\"] = df[\"yellow_cards\"].apply(self._count_events)\n        df[\"red_cards\"] = df[\"red_cards\"].apply(self._count_events)\n        df[\"win\"] = (df[\"goals_for\"] &gt; df[\"goals_against\"]).astype(int)\n        df[\"draw\"] = (df[\"goals_for\"] == df[\"goals_against\"]).astype(int)\n        df[\"loss\"] = (df[\"goals_for\"] &lt; df[\"goals_against\"]).astype(int)\n        df[\"points\"] = df[\"win\"] * 3 + df[\"draw\"]\n        df[\"fair_play\"] = -df[\"yellow_cards\"] - 2 * df[\"red_cards\"]\n        return df\n\n    def get_results(self) -&gt; pd.DataFrame:\n        results = (\n            self.matches.groupby(\"team\")\n            .agg(\n                GP=(\"team\", \"count\"),\n                W=(\"win\", \"sum\"),\n                D=(\"draw\", \"sum\"),\n                L=(\"loss\", \"sum\"),\n                GF=(\"goals_for\", \"sum\"),\n                GA=(\"goals_against\", \"sum\"),\n                FP=(\"fair_play\", \"sum\"),\n                Points=(\"points\", \"sum\"),\n            )\n            .reset_index()\n        )\n        results[\"GD\"] = results[\"GF\"] - results[\"GA\"]\n        results = results[\n            [\"team\", \"GP\", \"W\", \"D\", \"L\", \"GF\", \"GA\", \"GD\", \"FP\", \"Points\"]\n        ]\n        return results.sort_values(\n            by=[\"Points\", \"GD\"], ascending=False, ignore_index=True\n        ).rename(columns={\"team\": \"Team\"})\n\n    def top_scorers(\n        self, include_penalties: bool = True, top_n: int = 10\n    ) -&gt; pd.DataFrame:\n        parser = lambda x: [e.split(\"|\")[2].strip() for e in self._parse_events(x)]\n\n        goals_play = pd.concat(\n            [\n                self._explode_events(self.data, \"home_goal_long\", \"home_team\", parser),\n                self._explode_events(self.data, \"away_goal_long\", \"away_team\", parser),\n            ],\n            ignore_index=True,\n        )\n\n        dfs = [goals_play]\n\n        if include_penalties:\n            penalties = pd.concat(\n                [\n                    self._explode_events(\n                        self.data,\n                        \"home_penalty_goal\",\n                        \"home_team\",\n                        self._parse_penalty_goals,\n                    ),\n                    self._explode_events(\n                        self.data,\n                        \"away_penalty_goal\",\n                        \"away_team\",\n                        self._parse_penalty_goals,\n                    ),\n                ],\n                ignore_index=True,\n            )\n            dfs.append(penalties)\n\n        scorers = (\n            pd.concat(dfs, ignore_index=True)\n            .value_counts([\"player\", \"team\"])\n            .reset_index(name=\"Goals\")\n            .sort_values(\"Goals\", ascending=False)\n            .reset_index(drop=True)\n        )\n\n        scorers[\"Position\"] = (\n            scorers[\"Goals\"].rank(method=\"min\", ascending=False).astype(int)\n        )\n        scorers = scorers[[\"Position\", \"player\", \"team\", \"Goals\"]].rename(\n            columns={\"player\": \"Player\", \"team\": \"Team\"}\n        )\n\n        return scorers.sort_values([\"Position\", \"Player\"], ignore_index=True).head(\n            top_n\n        )\n\n    def world_cup_summary(self) -&gt; pd.DataFrame:\n        summary = (\n            self.matches.groupby([\"Year\", \"Host\", \"team\"])\n            .agg(\n                GP=(\"team\", \"count\"),\n                GF=(\"goals_for\", \"sum\"),\n                GF_avg=(\"goals_for\", \"mean\"),\n                GA=(\"goals_against\", \"sum\"),\n                GA_avg=(\"goals_against\", \"mean\"),\n                W=(\"win\", \"sum\"),\n                D=(\"draw\", \"sum\"),\n                L=(\"loss\", \"sum\"),\n            )\n            .reset_index()\n        )\n\n        assists = (\n            pd.concat(\n                [\n                    self._count_goal_assists(self.data, \"home_goal_long\", \"home_team\"),\n                    self._count_goal_assists(self.data, \"away_goal_long\", \"away_team\"),\n                ],\n                ignore_index=True,\n            )\n            .groupby([\"Year\", \"Host\", \"team\"], as_index=False)[\"assists\"]\n            .sum()\n        )\n\n        summary = summary.merge(assists, on=[\"Year\", \"Host\", \"team\"], how=\"left\")\n        summary[\"assists\"] = summary[\"assists\"].fillna(0)\n        summary[\"Assist Avg\"] = summary[\"assists\"] / summary[\"GP\"]\n\n        summary = summary[\n            [\n                \"Year\",\n                \"Host\",\n                \"team\",\n                \"GP\",\n                \"GF\",\n                \"GF_avg\",\n                \"GA\",\n                \"GA_avg\",\n                \"W\",\n                \"D\",\n                \"L\",\n                \"Assist Avg\",\n            ]\n        ]\n        summary.columns = [\n            \"Year\",\n            \"Host\",\n            \"Team\",\n            \"GP\",\n            \"GF\",\n            \"GF Avg\",\n            \"GA\",\n            \"GA Avg\",\n            \"W\",\n            \"D\",\n            \"L\",\n            \"Assist Avg\",\n        ]\n\n        return summary.sort_values(\n            by=[\"Year\", \"GF\"], ascending=[True, False], ignore_index=True\n        )",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#análisis-de-variables",
    "href": "case1.html#análisis-de-variables",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "1. Análisis de variables",
    "text": "1. Análisis de variables\nSe debe realizar un análisis donde identifique las variables del conjunto de datos mostrando los valores nulos, duplicados y el tipo de variable.\nPara el análisis de las variables, se usará la clase definida en la Sección 2.1.1 utilizando la función summary().\n\nanalysis_wc = AnalysisService(world_cup)\nanalysis_matches = AnalysisService(matches)\n\nanalysis_wc.summary()\nanalysis_matches.summary()\n\n\n0 duplicated rows\n          Column  # Rows  # Nulls    Type\n0           Year       9        0   int64\n1           Host       9        0  object\n2          Teams       9        0   int64\n3       Champion       9        1  object\n4      Runner-Up       9        1  object\n5     TopScorrer       9        0  object\n6     Attendance       9        0   int64\n7  AttendanceAvg       9        0   int64\n8        Matches       9        0   int64\n\n0 duplicated rows\n                             Column  # Rows  # Nulls     Type\n0                         home_team     348        0   object\n1                         away_team     348        0   object\n2                        home_score     348        0    int64\n3                           home_xg     348      232  float64\n4                      home_penalty     348      337  float64\n5                        away_score     348        0    int64\n6                           away_xg     348      232  float64\n7                      away_penalty     348      337  float64\n8                      home_manager     348      180   object\n9                      home_captain     348      180   object\n10                     away_manager     348      180   object\n11                     away_captain     348      180   object\n12                       Attendance     348        0    int64\n13                            Venue     348        0   object\n14                        Officials     348        3   object\n15                            Round     348        0   object\n16                             Date     348        0   object\n17                            Score     348        0   object\n18                          Referee     348        7   object\n19                            Notes     348      328   object\n20                             Host     348        0   object\n21                             Year     348        0    int64\n22                        home_goal     348       96   object\n23                        away_goal     348      148   object\n24                   home_goal_long     348       96   object\n25                   away_goal_long     348      148   object\n26                    home_own_goal     348      330   object\n27                    away_own_goal     348      335   object\n28                home_penalty_goal     348      294   object\n29                away_penalty_goal     348      313   object\n30           home_penalty_miss_long     348      335   object\n31           away_penalty_miss_long     348      341   object\n32  home_penalty_shootout_goal_long     348      337   object\n33  away_penalty_shootout_goal_long     348      337   object\n34  home_penalty_shootout_miss_long     348      340   object\n35  away_penalty_shootout_miss_long     348      338   object\n36                    home_red_card     348      340   object\n37                    away_red_card     348      337   object\n38             home_yellow_red_card     348      340   object\n39             away_yellow_red_card     348      345   object\n40            home_yellow_card_long     348      135   object\n41            away_yellow_card_long     348      118   object\n42          home_substitute_in_long     348        4   object\n43          away_substitute_in_long     348        5   object",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#validación-entre-tablas",
    "href": "case1.html#validación-entre-tablas",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "2. Validación entre tablas",
    "text": "2. Validación entre tablas\nSe debe realizar una validación cruzada entre las tablas, identifique los campos que relacionan las tablas y si existen datos faltantes en dichos campos.\nPara el análisis de las variables, se usará la clase definida en la Sección 2.1.1 utilizando la función related_columns().\n\nAnalysisService.related_columns(world_cup, matches)\n\n\nCommon columns: {'Attendance', 'Host', 'Year'}\n\n       column  df1_nulls  df2_nulls  only_df1  only_df2\n0  Attendance          0          0         9       254\n1        Host          0          0         0         0\n2        Year          0          0         0         0",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#tabla-de-posiciones",
    "href": "case1.html#tabla-de-posiciones",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "3. Tabla de posiciones",
    "text": "3. Tabla de posiciones\nSe debe elaborar la tabla de posiciones del mundial realizado en 1991. Tenga en cuenta que cada partido ganado da 3 puntos, cada parti do empatado da 1 punto. Así mismo, las tarjetas amarillas suman -1 punto para juego limpio y las tarjetas rojas – 2 puntos a juego limpio.\nLa tabla debe tener la siguiente estructura: Equipo | Partidos Jugados (PJ) | Partidos Ganados (PG) | Partidos Empatados (PE) | Partidos Perdidos (PP)| Goles a Favor (GF) | Goles en Contra (GC) | Diferencia de Goles (GF – GC) | Juego Limpio (JL) | Puntos\nPara esto, debemos crear una copia del dataframe matches filtrada por el año 1991.\n\nmatches_1991 = matches[matches['Year'] == 1991].copy()\n\nY, para calcular la tabla de posiciones, se usará la clase definida en la Sección 2.1.2 utilizando la función get_results().\n\nresults = ResultsService(matches_1991)\ntable_1991 = results.get_results()\nprint(table_1991)\n\n              Team  GP  W  D  L  GF  GA  GD  FP  Points\n0    United States   6  6  0  0  25   5  20  -4      18\n1           Sweden   6  4  0  2  18   7  11  -6      12\n2           Norway   6  4  0  2  14  10   4  -4      12\n3          Germany   6  4  0  2  13  10   3  -3      12\n4         China PR   4  2  1  1  10   4   6  -2       7\n5            Italy   4  2  0  2   8   5   3  -3       6\n6          Denmark   4  1  1  2   7   6   1  -2       4\n7           Brazil   3  1  0  2   1   7  -6  -4       3\n8   Chinese Taipei   4  1  0  3   2  15 -13  -1       3\n9          Nigeria   3  0  0  3   0   7  -7  -2       0\n10     New Zealand   3  0  0  3   1  11 -10   0       0\n11           Japan   3  0  0  3   0  12 -12  -1       0",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#tabla-de-goleadoras",
    "href": "case1.html#tabla-de-goleadoras",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "4. Tabla de goleadoras",
    "text": "4. Tabla de goleadoras\nSe debe elaborar la tabla de goleadoras del mundial de 2023.\nPara esto, debemos crear una copia del dataframe matches filtrada por el año 2023.\n\nmatches_2023 = matches[matches['Year'] == 2023].copy()\n\nEsta tabla será calculada utilizando la clase definida en la Sección 2.1.2 utilizando la función top_scorers().\n\nresults = ResultsService(matches_2023)\ntop_scorers_2023 = results.top_scorers()\nprint(top_scorers_2023)\n\n   Position             Player         Team  Goals\n0         1    Hinata Miyazawa        Japan      5\n1         2     Alexandra Popp      Germany      4\n2         2    Amanda Ilestedt       Sweden      4\n3         2         Jill Roord  Netherlands      4\n4         2   Kadidiatou Diani       France      4\n5         6     Aitana Bonmatí        Spain      3\n6         6       Alba Redondo        Spain      3\n7         6      Alessia Russo      England      3\n8         6         Ary Borges       Brazil      3\n9         6  Eugénie Le Sommer       France      3",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#tabla-analítica",
    "href": "case1.html#tabla-analítica",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "5. Tabla analítica",
    "text": "5. Tabla analítica\nDebe construir una rutina cuya salida sea UNA ÚNICA TABLA que muestre:\nAño | Host | Equipo | Partidos Jugados | Goles Totales marcados | Promedio de Goles marcados | Goles Totales recibidos | promedio de goles recibidos | partidos totales ganados | partidos totales perdidos | partidos totales empatados | promedio de asistencia por equipo.\nEsta tabla será calculada utilizando la clase definida en la Sección 2.1.2 utilizando la función world_cup_summary().\n\nresults = ResultsService(matches)\nsummary = results.world_cup_summary()\nprint(summary)\n\n     Year                    Host                 Team  GP  GF    GF Avg  GA  \\\n0    1991                China PR        United States   6  25  4.166667   5   \n1    1991                China PR               Sweden   6  18  3.000000   7   \n2    1991                China PR               Norway   6  14  2.333333  10   \n3    1991                China PR              Germany   6  13  2.166667  10   \n4    1991                China PR             China PR   4  10  2.500000   4   \n..    ...                     ...                  ...  ..  ..       ...  ..   \n163  2023  Australia, New Zealand          New Zealand   3   1  0.333333   1   \n164  2023  Australia, New Zealand          Philippines   3   1  0.333333   8   \n165  2023  Australia, New Zealand  Republic of Ireland   3   1  0.333333   3   \n166  2023  Australia, New Zealand                Haiti   3   0  0.000000   4   \n167  2023  Australia, New Zealand              Vietnam   3   0  0.000000  12   \n\n       GA Avg  W  D  L  Assist Avg  \n0    0.833333  6  0  0    0.000000  \n1    1.166667  4  0  2    0.000000  \n2    1.666667  4  0  2    0.000000  \n3    1.666667  4  0  2    0.000000  \n4    1.000000  2  1  1    0.000000  \n..        ... .. .. ..         ...  \n163  0.333333  1  1  1    0.333333  \n164  2.666667  1  0  2    0.333333  \n165  1.000000  0  1  2    0.000000  \n166  1.333333  0  0  3    0.000000  \n167  4.000000  0  0  3    0.000000  \n\n[168 rows x 12 columns]",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#cómo-ha-cambiado-el-promedio-de-goles-por-partido-a-lo-largo-de-los-torneos",
    "href": "case1.html#cómo-ha-cambiado-el-promedio-de-goles-por-partido-a-lo-largo-de-los-torneos",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "1. ¿Cómo ha cambiado el promedio de goles por partido a lo largo de los torneos?",
    "text": "1. ¿Cómo ha cambiado el promedio de goles por partido a lo largo de los torneos?\nPara hallar el promedio de goles realizados por partido, debemos tomar los goles marcados por equipo. Para ello, usaremos la tabla summary obtenida en la sección anterior.\n\ngoals_trend = (\n    summary.groupby(\"Year\").agg({\"GF\": \"sum\", \"GA\": \"sum\"}).reset_index()\n)\n\ngoals_trend[\"Total Goals Avg\"] = (goals_trend[\"GF\"] + goals_trend[\"GA\"]) / 2\nprint(\"\\nAverage Goals Trend:\")\nprint(goals_trend)\n\n\nAverage Goals Trend:\n   Year   GF   GA  Total Goals Avg\n0  1991   99   99             99.0\n1  1995   99   99             99.0\n2  1999  122  122            122.0\n3  2003  105  105            105.0\n4  2007  111  111            111.0\n5  2011   86   86             86.0\n6  2015  146  146            146.0\n7  2019  146  146            146.0\n8  2023  164  164            164.0\n\n\n\n\n\n\n\n\n\n\n\nComo podemos observar, a medida que avanzan los años, el promedio de goles por partido ha aumentado. Esto puede deberse a factores como el aumento de la calidad de los equipos, la mejora en el entrenamiento y la tecnología utilizada en el juego. Además, también puede deberse a la introducción de nuevas reglas y cambios en el formato del torneo, como del aumento de equipos participantes.",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#cuáles-son-las-selecciones-con-mejor-desempeño-en-términos-de-victorias",
    "href": "case1.html#cuáles-son-las-selecciones-con-mejor-desempeño-en-términos-de-victorias",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "2. ¿Cuáles son las selecciones con mejor desempeño en términos de victorias?",
    "text": "2. ¿Cuáles son las selecciones con mejor desempeño en términos de victorias?\n\nbest_teams = (\n    summary.groupby(\"Team\")\n    .agg({\"W\": \"sum\", \"GP\": \"sum\", \"GF\": \"sum\", \"GA\": \"sum\"})\n    .reset_index()\n)\n\nbest_teams[\"Win Rate\"] = (best_teams[\"W\"] / best_teams[\"GP\"] * 100).round(2)\nbest_teams[\"GD\"] = best_teams[\"GF\"] - best_teams[\"GA\"]\n\nbest_teams = best_teams.sort_values(\"W\", ascending=False, ignore_index=True)\nprint(\"\\nTop 10 teams:\")\nprint(best_teams[[\"Team\", \"GP\", \"W\", \"Win Rate\", \"GD\"]].head(10))\n\n\nTop 10 teams:\n            Team  GP   W  Win Rate   GD\n0  United States  54  41     75.93  103\n1        Germany  47  30     63.83   87\n2         Sweden  47  28     59.57   34\n3         Norway  44  25     56.82   45\n4         Brazil  37  21     56.76   29\n5        England  33  20     60.61   22\n6          Japan  38  18     47.37   -8\n7       China PR  36  17     47.22   15\n8         France  24  13     54.17   20\n9    Netherlands  16  10     62.50   14\n\n\nEste resultado es interesante pues, si tuviesemos en cuenta el ratio de victorias y no solo la cantidad de partidos ganados, podríamos decir que el top 3 de selecciones con mejor desempeño en términos de ratio de victorias es:\n\nEstados Unidos\nAlemania\nPaises Bajos",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case1.html#existen-tendencias-en-los-equipos-dominantes-y-con-peor-desempeño",
    "href": "case1.html#existen-tendencias-en-los-equipos-dominantes-y-con-peor-desempeño",
    "title": "Caso 1: Análisis de la copa mundial femenina",
    "section": "3. ¿Existen tendencias en los equipos dominantes y con peor desempeño?",
    "text": "3. ¿Existen tendencias en los equipos dominantes y con peor desempeño?\nEsta es una pregunta bastante curiosa, pues no necesariamente una selección que logró ganar muchos mundiales en el pasado, se mantendrá como una selección dominante en el futuro. Pues, cada año nacen nuevos jugadores que pueden tener un gran impacto en el desempeño de sus selecciones.\n\ndominant_teams = best_teams[best_teams[\"GP\"] &gt;= 10].sort_values(\"Win Rate\", ascending=False)\nprint(\"Most dominant teams (min 10 games):\")\nprint(dominant_teams[[\"Team\", \"GP\", \"W\", \"Win Rate\", \"GD\"]].head(10))\n\nworst_teams = best_teams[best_teams[\"GP\"] &gt;= 10].sort_values(\"Win Rate\", ascending=True)\nprint(\"\\nWorst performing teams (min 10 games):\")\nprint(worst_teams[[\"Team\", \"GP\", \"W\", \"Win Rate\", \"GD\"]].head(10))\n\nMost dominant teams (min 10 games):\n             Team  GP   W  Win Rate   GD\n0   United States  54  41     75.93  103\n1         Germany  47  30     63.83   87\n9     Netherlands  16  10     62.50   14\n5         England  33  20     60.61   22\n2          Sweden  47  28     59.57   34\n3          Norway  44  25     56.82   45\n4          Brazil  37  21     56.76   29\n8          France  24  13     54.17   20\n12          Spain  14   7     50.00    9\n6           Japan  38  18     47.37   -8\n\nWorst performing teams (min 10 games):\n              Team  GP   W  Win Rate  GD\n34       Argentina  12   0      0.00 -35\n29     New Zealand  18   1      5.56 -26\n27  Korea Republic  13   1      7.69 -24\n14         Nigeria  30   5     16.67 -42\n18       Korea DPR  13   3     23.08  -8\n15         Denmark  18   5     27.78  -7\n11          Canada  30   9     30.00 -21\n10       Australia  33  10     30.30 -10\n16        Colombia  12   4     33.33  -3\n13           Italy  15   7     46.67   3\n\n\nCon esto podemos evidenciar lo mencionado anteriormente: que un equipo haya ganado muchos partidos en el pasado no necesariamente tendrá un buen desempeño en el futuro.\n\nteam_evolution = (\n    summary.groupby([\"Team\", \"Year\"]).agg({\"W\": \"sum\", \"GP\": \"sum\"}).reset_index()\n)\n\nteam_evolution[\"Win Rate\"] = (team_evolution[\"W\"] / team_evolution[\"GP\"] * 100).round(2)\n\nconsistency = (\n    team_evolution.groupby(\"Team\")\n    .agg({\"Win Rate\": [\"mean\", \"std\", \"count\"]})\n    .reset_index()\n)\nconsistency.columns = [\"Team\", \"Avg Win Rate\", \"Std Win Rate\", \"Tournaments\"]\nconsistency = consistency[consistency[\"Tournaments\"] &gt;= 3].sort_values(\n    \"Std Win Rate\"\n)\n\nprint(\"\\nMost consistent teams (min 3 tournaments):\")\nprint(consistency.head(10).reset_index(drop=True))\n\nprint(\"\\nMost inconsistent teams (min 3 tournaments):\")\nprint(consistency.tail(10).reset_index(drop=True))\n\n\nMost consistent teams (min 3 tournaments):\n             Team  Avg Win Rate  Std Win Rate  Tournaments\n0       Argentina      0.000000      0.000000            4\n1          Mexico      0.000000      0.000000            3\n2  Korea Republic      6.250000     12.500000            4\n3           Italy     44.165000     13.160407            4\n4     New Zealand      5.555000     13.606916            6\n5       Korea DPR     22.915000     15.773278            4\n6        China PR     45.623750     17.882370            8\n7         Denmark     26.666000     18.065929            5\n8         England     56.548333     18.683954            6\n9         Nigeria     14.814444     18.992364            9\n\nMost inconsistent teams (min 3 tournaments):\n            Team  Avg Win Rate  Std Win Rate  Tournaments\n0         Norway     53.518889     22.212675            9\n1         Canada     25.832500     22.307056            8\n2        Germany     61.798889     22.370461            9\n3      Australia     25.982500     22.869996            8\n4  United States     73.412222     24.353055            9\n5         Sweden     54.762222     25.394233            9\n6       Colombia     28.333333     30.138569            3\n7    Netherlands     56.903333     30.473235            3\n8          Japan     38.782222     31.871468            9\n9          Spain     36.903333     44.077410            3",
    "crumbs": [
      "Caso 1: Análisis de la copa mundial femenina"
    ]
  },
  {
    "objectID": "case2_analysis.html",
    "href": "case2_analysis.html",
    "title": "Caso 2: Análisis de Desempeño Estudiantil en Matemáticas",
    "section": "",
    "text": "Para la realización de este EDA, utilizaremos las siguientes librerías:\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.decomposition import PCA\n\nY configuraremos los siguientes parámetros:\n\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\nplt.rcParams['figure.figsize'] = (15, 10)",
    "crumbs": [
      "Caso 2: Desempeño estudiantes de matemáticas",
      "Análisis de los datos"
    ]
  },
  {
    "objectID": "case2_analysis.html#diccionario-de-datos",
    "href": "case2_analysis.html#diccionario-de-datos",
    "title": "Caso 2: Análisis de Desempeño Estudiantil en Matemáticas",
    "section": "3.1 Diccionario de datos",
    "text": "3.1 Diccionario de datos\n\ndata_dictionary = {}\n\nprint(f\"\\n{'Column':&lt;40} {'Type':&lt;15} {'Unique':&lt;10} {'Nulls':&lt;10} {'% Nulls'}\")\n\nfor col in df.columns:\n    dtype = str(df[col].dtype)\n    unique = df[col].nunique()\n    nulls = df[col].isnull().sum()\n    null_pct = (nulls / len(df)) * 100\n\n    data_dictionary[col] = {\n        \"dtype\": dtype,\n        \"unique\": int(unique),\n        \"nulls\": int(nulls),\n        \"% nulls\": round(float(null_pct), 2),\n        \"min\": float(df[col].min()) if df[col].dtype in ['int64', 'float64'] else None,\n        \"max\": float(df[col].max()) if df[col].dtype in ['int64', 'float64'] else None,\n        \"mean\": float(df[col].mean()) if df[col].dtype in ['int64', 'float64'] else None,\n        \"median\": float(df[col].median()) if df[col].dtype in ['int64', 'float64'] else None,\n        \"std\": float(df[col].std()) if df[col].dtype in ['int64', 'float64'] else None,\n        \"examples\": df[col].head(3).tolist() if dtype == 'object' else None\n    }\n\n    print(f\"{col:&lt;40} {dtype:&lt;15} {unique:&lt;10} {nulls:&lt;10} {null_pct:.2f}%\")\n\n\nColumn                                   Type            Unique     Nulls      % Nulls\nHours Studied                            int64           9          0          0.00%\nPrevious Scores                          int64           60         0          0.00%\nExtracurricular Activities               object          2          0          0.00%\nSleep Hours                              int64           6          0          0.00%\nSample Question Papers Practiced         int64           10         0          0.00%\nPerformance Index                        float64         91         0          0.00%",
    "crumbs": [
      "Caso 2: Desempeño estudiantes de matemáticas",
      "Análisis de los datos"
    ]
  },
  {
    "objectID": "case2_analysis.html#transformaciones-de-los-datos",
    "href": "case2_analysis.html#transformaciones-de-los-datos",
    "title": "Caso 2: Análisis de Desempeño Estudiantil en Matemáticas",
    "section": "3.2 Transformaciones de los datos",
    "text": "3.2 Transformaciones de los datos\nCon lo observado en el inciso anterior, podemos afirmar que los datos tienen una buena calidad en los datos ya que no hay valores nulos y los tipos de datos son consistentes.\n\nValidación de datos duplicados\nCuando pensamos en transformar los datos, es importante considerar la cantidad de datos duplicados. Veamos si nuestro dataset tiene datos duplicados y si se deben eliminar.\n\nprint(f\"Duplicates: {df.duplicated().sum()} rows\")\n\nDuplicates: 127 rows\n\n\nEsta cantidad de datos duplicados pueden ocurrir por varias razones, pero una muy clara es que, dado que son datos sobre el rendimiento académico de estudiantes, es posible que dos estudiantes o más puedan tener métodos similares de estudio.\nSin embargo, aunque el porcentaje de datos duplicados (1.27%) sea bajo debemos comprobar con analítica descriptiva si estos afectan significativamente antes y después de eliminarlos.\n\ndf.describe()\n\n\n\n\n\n\n\n\nHours Studied\nPrevious Scores\nSleep Hours\nSample Question Papers Practiced\nPerformance Index\n\n\n\n\ncount\n10000.000000\n10000.000000\n10000.000000\n10000.000000\n10000.000000\n\n\nmean\n4.992900\n69.445700\n6.530600\n4.583300\n55.224800\n\n\nstd\n2.589309\n17.343152\n1.695863\n2.867348\n19.212558\n\n\nmin\n1.000000\n40.000000\n4.000000\n0.000000\n10.000000\n\n\n25%\n3.000000\n54.000000\n5.000000\n2.000000\n40.000000\n\n\n50%\n5.000000\n69.000000\n7.000000\n5.000000\n55.000000\n\n\n75%\n7.000000\n85.000000\n8.000000\n7.000000\n71.000000\n\n\nmax\n9.000000\n99.000000\n9.000000\n9.000000\n100.000000\n\n\n\n\n\n\n\n\ndf.drop_duplicates().describe()\n\n\n\n\n\n\n\n\nHours Studied\nPrevious Scores\nSleep Hours\nSample Question Papers Practiced\nPerformance Index\n\n\n\n\ncount\n9873.000000\n9873.000000\n9873.000000\n9873.000000\n9873.000000\n\n\nmean\n4.992100\n69.441102\n6.531652\n4.583004\n55.216651\n\n\nstd\n2.589081\n17.325601\n1.697683\n2.867202\n19.208570\n\n\nmin\n1.000000\n40.000000\n4.000000\n0.000000\n10.000000\n\n\n25%\n3.000000\n54.000000\n5.000000\n2.000000\n40.000000\n\n\n50%\n5.000000\n69.000000\n7.000000\n5.000000\n55.000000\n\n\n75%\n7.000000\n85.000000\n8.000000\n7.000000\n70.000000\n\n\nmax\n9.000000\n99.000000\n9.000000\n9.000000\n100.000000\n\n\n\n\n\n\n\nComo podemos observar, la media y la desviación estándar de los datos duplicados es muy similar a la media de los datos sin duplicados, por lo que no afectan significativamente los datos.\n\n\nTipos de variables\nOtro tipo de de transformación que es importante a la hora de trabajar con modelos de ML son las variables categóricas. Estas variables pueden ser binarias o no binarias. En el caso de las variables binarias, podemos convertirlas en variables numéricas (0 o 1). En el caso de las variables no binarias, podemos convertirlas en variables numéricas utilizando técnicas como one-hot encoding.\nDe nuestro análisis podemos notar que Extracurricular Activities es una variable categórica cuyo valor puede ser Yes o No. Por lo tanto, convertiremos esta variable en una variable binaria (0 o 1).\n\ndf_transf = df.copy()\n\ndf_transf['Extracurricular Activities'] = df_transf['Extracurricular Activities'].map({'Yes': 1, 'No': 0})\n\nAdemás, si queremos realizar un modelo de clasificación, es importante tener una variable objetivo categórica. Teniendo en cuenta que nuestra variable target es Performance Index, haremos una transformación para obtener una variable categórica que identifique si un estudiante tiene un rendimiento bajo, lo que permitiría a las escuelas identificar estudiantes en riesgos académicos.\n\nper_25 = df_transf['Performance Index'].quantile(0.25)\n\ndf_transf['Low Performance'] = (df_transf['Performance Index'] &lt; per_25).astype(int)\n\nDe esta forma, un estudiante tendrá un bajo rendimiento si su índice está dentro del 25% más bajo de la población, lo que permite identificar el cuartil de estudiantes con mayor riesgo académico.\n\n\nEscalado de variables\nDado que el objetivo de este análisis es predecir el rendimiento académico de los estudiantes, es importante escalar las variables numéricas para que todas tengan la misma escala y para obtener una mejor convergencia de algoritmos.\nEn este caso, utilizaremos el método de escalado estándar (StandardScaler) para normalizar las variables numéricas que consiste en restar la media y dividir por la desviación estándar.\n\nfeatures_to_scale = [\n    'Hours Studied', 'Previous Scores', 'Sleep Hours',\n    'Sample Question Papers Practiced'\n]\n\nscaler = StandardScaler()\ndf_transf[features_to_scale] = scaler.fit_transform(df_transf[features_to_scale])\n\nLo que nos deja con\n\ndf_transf[features_to_scale].describe()\n\n\n\n\n\n\n\n\nHours Studied\nPrevious Scores\nSleep Hours\nSample Question Papers Practiced\n\n\n\n\ncount\n1.000000e+04\n1.000000e+04\n1.000000e+04\n1.000000e+04\n\n\nmean\n1.016076e-16\n-1.286082e-16\n1.275424e-16\n-1.680434e-16\n\n\nstd\n1.000050e+00\n1.000050e+00\n1.000050e+00\n1.000050e+00\n\n\nmin\n-1.542149e+00\n-1.697914e+00\n-1.492294e+00\n-1.598526e+00\n\n\n25%\n-7.697033e-01\n-8.906381e-01\n-9.025945e-01\n-9.009822e-01\n\n\n50%\n2.742182e-03\n-2.570019e-02\n2.768051e-01\n1.453332e-01\n\n\n75%\n7.751877e-01\n8.969003e-01\n8.665048e-01\n8.428768e-01\n\n\nmax\n1.547633e+00\n1.704176e+00\n1.456205e+00\n1.540420e+00",
    "crumbs": [
      "Caso 2: Desempeño estudiantes de matemáticas",
      "Análisis de los datos"
    ]
  },
  {
    "objectID": "case2_analysis.html#análisis-descriptivo-de-las-variables",
    "href": "case2_analysis.html#análisis-descriptivo-de-las-variables",
    "title": "Caso 2: Análisis de Desempeño Estudiantil en Matemáticas",
    "section": "3.3 Análisis descriptivo de las variables",
    "text": "3.3 Análisis descriptivo de las variables\nEsta descripción de las variables se interpretará con el análisis descriptivo de las variables antes de la transformación pues, estas transformaciones no afectan la distribución de las variables pero si su interpretabilidad.\nPara las variables categóricas tenemos:\n\nprint(df_transf['Extracurricular Activities'].value_counts())\nprint(df_transf['Low Performance'].value_counts())\n\nExtracurricular Activities\n0    5052\n1    4948\nName: count, dtype: int64\nLow Performance\n0    7618\n1    2382\nName: count, dtype: int64\n\n\n\nFeatures\n\nHours Studied Los estudiantes estudian entre 1 y 9 horas por semana, con un promedio de 4.99 horas (std=2.59). La distribución muestra que:\n\n\nEl 50% de los estudiantes estudia 5 horas o menos (mediana=5)\nEl 25% estudia 3 horas o menos (Q1)\nEl 25% estudia 7 horas o más (Q3)\n\nHallazgo: Existe una alta variabilidad en los hábitos de estudio entre estudiantes (coeficiente de variación del 52%), lo que sugiere diferencias significativas en la dedicación académica y podría ser un factor diferenciador en el rendimiento.\n\nPrevious Scores Los puntajes académicos previos oscilan entre 40 y 99 puntos, con una media de 69.45 (std=17.34). La distribución indica:\n\n\nEl 50% tiene puntajes entre 54 y 85 puntos (IQR=31)\nEl 25% tiene puntajes inferiores a 54 puntos\nMediana de 69 puntos, similar a la media (distribución simétrica)\n\nHallazgo: La base académica previa es heterogénea con una dispersión considerable (CV=25%). Esto sugiere que el rendimiento histórico será un predictor importante, ya que estudiantes con bases débiles (&lt;54) podrían estar en mayor riesgo.\n\nExtracurricular Activities Variable categórica binaria con distribución:\n\n\n49.48% participa en actividades extracurriculares (Yes=1)\n50.52% no participa (No=0)\n\nHallazgo: El dataset está perfectamente balanceado en esta variable, lo que permitirá analizar de forma equitativa el impacto de las actividades extracurriculares en el rendimiento académico sin sesgos de muestreo.\n\nSleep Hours Sleep Hours (Horas de Sueño) Las horas de sueño promedian 6.53 horas diarias (std=1.70), con un rango de 4 a 9 horas:\n\n\nEl 50% duerme entre 5 y 8 horas (IQR=3)\nMediana de 7 horas\nDistribución concentrada alrededor de 6-7 horas\n\nHallazgo: La mayoría de estudiantes duerme en el rango recomendado para adolescentes (7-9 horas), aunque existe un 25% que duerme 5 horas o menos, lo que podría afectar negativamente su capacidad cognitiva y rendimiento académico.\n\nSample Question Papers Practiced Los estudiantes practican en promedio 4.58 ejercicios (std=2.87), con un rango de 0 a 9:\n\n\nEl 50% practica entre 2 y 7 ejercicios (IQR=5)\nMediana de 5 ejercicios\nAlta variabilidad (CV=63%)\n\nHallazgo: Existe una dispersión considerable en la práctica de ejercicios, con algunos estudiantes sin práctica alguna (mínimo=0) y otros altamente comprometidos (máximo=9). Esta variable muestra la mayor variabilidad relativa, lo que la convierte en un potencial diferenciador clave del rendimiento.\n\n\nTarget\n\nPerformance Index El rendimiento académico presenta una media de 55.22 puntos (std=19.21), con un rango de 10 a 100 puntos:\n\n\nPercentil 25: 40 puntos (bajo rendimiento)\nPercentil 50: 55 puntos (mediana)\nPercentil 75: 71 puntos (alto rendimiento)\nRango intercuartílico: 31 puntos\n\nHallazgo principal: La alta dispersión (std=19.21, CV=35%) indica que el rendimiento académico es muy variable entre estudiantes. La distribución es aproximadamente simétrica (media ≈ mediana), lo que sugiere que no hay sesgos extremos hacia rendimientos muy bajos o muy altos. Esta variabilidad confirma la necesidad de identificar factores predictores para explicar estas diferencias.\n\nLow Performance Variable binaria derivada del percentil 25 del Performance Index:\n\n\n25% de estudiantes en riesgo académico (Low Performance = 1, PI &lt; 40)\n75% con rendimiento adecuado (Low Performance = 0, PI ≥ 40)\n\nHallazgo: 1 de cada 4 estudiantes requiere intervención académica, lo que representa un desafío significativo para las instituciones educativas. Esta proporción justifica el desarrollo de modelos predictivos para identificación temprana de estudiantes en riesgo.",
    "crumbs": [
      "Caso 2: Desempeño estudiantes de matemáticas",
      "Análisis de los datos"
    ]
  },
  {
    "objectID": "case2_analysis.html#prueba-de-hipótesis",
    "href": "case2_analysis.html#prueba-de-hipótesis",
    "title": "Caso 2: Análisis de Desempeño Estudiantil en Matemáticas",
    "section": "3.4 Prueba de Hipótesis",
    "text": "3.4 Prueba de Hipótesis\nPara responder la pregunta planteada: “¿Existen diferencias estadísticas entre el puntaje final (Performance Index) y la asistencia a actividades extracurriculares?” debemos realizar una prueba de hipótesis para comparar las medias de ambos grupos. De esta forma, con un nivel de significancia \\(\\alpha = 0.05\\), tenemos:\n\\[\n\\begin{aligned}\nH_0 &: \\mu_1 = \\mu_2  \\\\\nH_1 &: \\mu_1 \\neq \\mu_2\n\\end{aligned}\n\\]\ndonde \\(\\mu_1\\) y \\(\\mu_2\\) representan las medias de los puntajes de los estudiantes que asisten y no asisten a actividades extracurriculares, respectivamente.\n\nAnálisis por grupo\n\nwith_extra = df_transf[df_transf['Extracurricular Activities'] == 1]['Performance Index']\nwithout_extra = df_transf[df_transf['Extracurricular Activities'] == 0]['Performance Index']\n\nprint(with_extra.describe())\nprint(without_extra.describe())\n\ncount    4948.000000\nmean       55.700889\nstd        19.264416\nmin        11.000000\n25%        41.000000\n50%        55.000000\n75%        71.000000\nmax       100.000000\nName: Performance Index, dtype: float64\ncount    5052.000000\nmean       54.758511\nstd        19.152068\nmin        10.000000\n25%        40.000000\n50%        55.000000\n75%        70.000000\nmax        99.000000\nName: Performance Index, dtype: float64\n\n\n\n\nVerificación de supuestos\nPara la prueba de hipótesis es necesario verificar que las muestras sean independientes y que las varianzas sean iguales. De esta forma, debemos realizar una prueba de normalidad (Shapiro-Wilk) y una prueba de igualdad de varianzas (Levene).\n\nprint(f\"Mean Difference: {with_extra.mean() - without_extra.mean():.4f}\")\n\nMean Difference: 0.9424\n\n\n\nPrueba de normalidad\n\nstat_with, p_with = stats.shapiro(with_extra)\nstat_without, p_without = stats.shapiro(without_extra)\n\nprint(\"Shapiro-Wilk Test:\")\nprint(f\"With Extra: {stat_with:.6f}, p-value: {p_with:.6f}\")\nprint(f\"Without Extra: {stat_without:.6f}, p-value: {p_without:.6f}\")\n\nShapiro-Wilk Test:\nWith Extra: 0.983235, p-value: 0.000000\nWithout Extra: 0.984866, p-value: 0.000000\n\n\n\n\nPrueba de igualdad de varianzas\n\nstat, p = stats.levene(with_extra, without_extra)\n\nprint(\"Levene Test:\")\nprint(f\"Statistic: {stat:.6f}, p-value: {p:.6f}\")\n\nLevene Test:\nStatistic: 0.427227, p-value: 0.513368\n\n\nDado que los datos no cumplen con el supuesto de normalidad, deberíamos usar una prueba no paramétrica como la U de Mann-Whitney. Sin embargo, dado el tamaño de las muestras (\\(n_1 = 4948, n_2 = 5052\\)), por el teorema central del límite podemos usar la prueba paramétrica t-test.\n\n\n\nPrueba t\n\nstat, p = stats.ttest_ind(with_extra, without_extra)\n\nprint(\"T-Test:\")\nprint(f\"Statistic: {stat:.6f}, p-value: {p:.6f}\")\n\nT-Test:\nStatistic: 2.452987, p-value: 0.014184\n\n\n\n\nPrueba U de Mann-Whitney\n\nstat, p = stats.mannwhitneyu(with_extra, without_extra)\n\nprint(\"Mann-Whitney U Test:\")\nprint(f\"Statistic: {stat:.6f}, p-value: {p:.6f}\")\n\nMann-Whitney U Test:\nStatistic: 12814910.500000, p-value: 0.028425\n\n\nCon base a los resultados obtenidos (p-valores &lt; 0.05), podemos rechazar la hipótesis nula y concluir que existen diferencias en el Performance Index entre estudiantes que asisten y no asisten a actividades extracurriculares.\nLos estudiantes que participan en actividades extracurriculares presentan un rendimiento académico significativamente superior a aquellos que no participan (aproximadamente 0.94 puntos más). Aunque la diferencia es estadísticamente significativa, es importante notar que la magnitud es relativamente pequeña (menos de 1 punto), lo que sugiere que las actividades extracurriculares tienen un impacto positivo pero modesto en el rendimiento académico.\n\n\nClustering de estudiantes según sus características\nPara identificar los grupos o conglomerados de estudiantes, se aplicará el método del codo y el análisis de silueta para determinar el número óptimo de clusters.\n\ncluster_features = features_to_scale + ['Extracurricular Activities']\nX_cluster = df_transf[cluster_features].copy()\n\ninertias = []\nsilhouette_scores = []\nK_range = range(2, 11)\n\nfor k in K_range:\n    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n    kmeans.fit(X_cluster)\n    inertias.append(kmeans.inertia_)\n\n    labels = kmeans.predict(X_cluster)\n    score = silhouette_score(X_cluster, labels)\n    silhouette_scores.append(score)\n\nprint(\"Silhouette Scores:\")\nfor k, score in zip(K_range, silhouette_scores):\n    print(f\"k={k}: {score:.4f}\")\n\nSilhouette Scores:\nk=2: 0.1773\nk=3: 0.1639\nk=4: 0.1725\nk=5: 0.1783\nk=6: 0.1774\nk=7: 0.1883\nk=8: 0.2020\nk=9: 0.1932\nk=10: 0.1925\n\n\n\nfig, axes = plt.subplots(2, 1, figsize=(8, 15))\n\nax1 = axes[0]\nax1.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\nax1.set_xlabel('# Clusters (k)')\nax1.set_ylabel('Inertia (WCSS)')\nax1.set_title('Elbow Method')\nax1.grid(True, alpha=0.3)\n\nax2 = axes[1]\nax2.plot(K_range, silhouette_scores, 'go-', linewidth=2, markersize=8)\nax2.set_xlabel('# Clusters (k)')\nax2.set_ylabel('Silhouette Score')\nax2.set_title('Silhouette Analysis')\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nComo podemos observar, el número óptimo de clusters es 4, pues aporta un balance entre la simplicidad y calidad de los grupos identificados. Presenta un score de silhouette aceptable (0.1725), similar al obtenido con un número de clusteres mayor. Además permite identificar perfiles claros: bajo, medio-bajo, medio-alto, alto rendimiento por lo que facilita la toma de decisiones y la implementación de intervenciones educativas.\n\noptimal_k = 4\nkmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\ndf_transf['Cluster'] = kmeans_final.fit_predict(X_cluster)\n\nprint(f\"Student distribution by cluster:\")\nprint(df_transf['Cluster'].value_counts().sort_index())\n\nStudent distribution by cluster:\nCluster\n0    2564\n1    2454\n2    2533\n3    2449\nName: count, dtype: int64\n\n\n\nfor i in range(optimal_k):\n    cluster_data = df[df_transf['Cluster'] == i]\n\n    print(f\"Cluster {i} (n = {len(cluster_data)} students, {len(cluster_data)/len(df)*100:.1f}%)\")\n    print(f\"Hours studied: {cluster_data['Hours Studied'].mean():.2f} hours/week\")\n    print(f\"Previous scores: {cluster_data['Previous Scores'].mean():.2f} points\")\n    print(f\"Sleep hours: {cluster_data['Sleep Hours'].mean():.2f} hours/day\")\n    print(f\"Sample questions practiced: {cluster_data['Sample Question Papers Practiced'].mean():.2f} exercises\")\n    print(f\"Performance index: {cluster_data['Performance Index'].mean():.2f} points\")\n\n    with_extra_pct = (cluster_data['Extracurricular Activities'] == 'Yes').sum() / len(cluster_data) * 100\n    print(f\"Extracurricular activities: {with_extra_pct:.1f}%\")\n\n    perf_mean = cluster_data['Performance Index'].mean()\n    if perf_mean &gt;= df['Performance Index'].quantile(0.75):\n        category = \"high\"\n    elif perf_mean &gt;= df['Performance Index'].quantile(0.50):\n        category = \"medium-high\"\n    elif perf_mean &gt;= df['Performance Index'].quantile(0.25):\n        category = \"medium-low\"\n    else:\n        category = \"low\"\n\n    print(f\"Performance level: {category}\")\n    print()\n\nCluster 0 (n = 2564 students, 25.6%)\nHours studied: 6.97 hours/week\nPrevious scores: 69.54 points\nSleep hours: 4.88 hours/day\nSample questions practiced: 4.76 exercises\nPerformance index: 60.19 points\nExtracurricular activities: 51.1%\nPerformance level: medium-high\n\nCluster 1 (n = 2454 students, 24.5%)\nHours studied: 7.24 hours/week\nPrevious scores: 69.23 points\nSleep hours: 8.10 hours/day\nSample questions practiced: 4.72 exercises\nPerformance index: 62.23 points\nExtracurricular activities: 48.1%\nPerformance level: medium-high\n\nCluster 2 (n = 2533 students, 25.3%)\nHours studied: 2.96 hours/week\nPrevious scores: 69.36 points\nSleep hours: 6.57 hours/day\nSample questions practiced: 1.72 exercises\nPerformance index: 48.77 points\nExtracurricular activities: 48.6%\nPerformance level: medium-low\n\nCluster 3 (n = 2449 students, 24.5%)\nHours studied: 2.77 hours/week\nPrevious scores: 69.65 points\nSleep hours: 6.65 hours/day\nSample questions practiced: 7.23 exercises\nPerformance index: 49.69 points\nExtracurricular activities: 50.1%\nPerformance level: medium-low\n\n\n\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_cluster)\n\nprint(f\"Explained variance:\")\nprint(f\"PC1: {pca.explained_variance_ratio_[0]*100:.2f}%\")\nprint(f\"PC2: {pca.explained_variance_ratio_[1]*100:.2f}%\")\nprint(f\"Total: {sum(pca.explained_variance_ratio_)*100:.2f}%\")\n\nExplained variance:\nPC1: 23.97%\nPC2: 23.80%\nTotal: 47.76%\n\n\n\nfig, axes = plt.subplots(2, 1, figsize=(8, 12))\n\nax1 = axes[0]\nscatter = ax1.scatter(\n    X_pca[:, 0], X_pca[:, 1],\n    c=df_transf['Cluster'], cmap='viridis',\n    alpha=0.6, edgecolors='black', s=30\n)\nax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\nax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\nax1.set_title('Clusters on PCA')\nax1.grid(True, alpha=0.3)\nplt.colorbar(scatter, ax=ax1, label='Cluster')\n\ncenters_pca = pca.transform(kmeans_final.cluster_centers_)\nax1.scatter(\n    centers_pca[:, 0], centers_pca[:, 1],\n    c='red', marker='X', s=300, edgecolors='black',\n    linewidths=2, label='Centroids'\n)\nax1.legend()\n\nax2 = axes[1]\ncluster_counts = df_transf['Cluster'].value_counts().sort_index()\ncolors = plt.cm.viridis(np.linspace(0, 1, optimal_k))\nax2.bar(\n    cluster_counts.index, cluster_counts.values,\n    color=colors, edgecolor='black', alpha=0.7\n)\nax2.set_xlabel('Cluster')\nax2.set_ylabel('# Students')\nax2.set_title('Distribution of Students by Cluster')\nax2.set_xticks(range(optimal_k))\nax2.grid(True, alpha=0.3, axis='y')\n\nfor i, val in enumerate(cluster_counts.values):\n    ax2.text(i, val, str(val), ha='center', va='bottom', fontweight='bold')\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Caso 2: Desempeño estudiantes de matemáticas",
      "Análisis de los datos"
    ]
  },
  {
    "objectID": "case2_modeling.html",
    "href": "case2_modeling.html",
    "title": "Caso 2: Análisis de Desempeño Estudiantil en Matemáticas",
    "section": "",
    "text": "Para la construcción de los modelos, utilizaremos las siguientes librerías:\n\nProcesamiento de datos\n\n\nimport os\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\n\nModelos de regresión\n\n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n\nModelos de clasificación\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, classification_report, roc_auc_score, roc_curve\n)\n\n\nOtras librerías\n\n\nimport joblib\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nComparación de modelos\n\n\ndef compare_top_models(results_df, model_type='classification'):\n    if model_type == 'regression':\n        top_3 = results_df.nsmallest(3, 'RMSE_Test')\n        metric = 'RMSE_Test'\n    else:\n        top_3 = results_df.nlargest(3, 'F1-Score')\n        metric = 'F1-Score'\n\n    for i, (idx, row) in enumerate(top_3.iterrows(), 1):\n        print(f\"{i}. {row['Model']}\")\n        if model_type == 'regression':\n            print(f\"RMSE Test: {row['RMSE_Test']:.4f}\")\n            print(f\"MAE Test: {row['MAE_Test']:.4f}\")\n            print(f\"R² Test: {row['R2_Test']:.4f}\")\n            print(f\"CV RMSE: {row['CV_RMSE']:.4f}\")\n        else:\n            print(f\"Accuracy: {row['Accuracy_Test']:.4f}\")\n            print(f\"Precision: {row['Precision']:.4f}\")\n            print(f\"Recall: {row['Recall']:.4f}\")\n            print(f\"F1-Score: {row['F1-Score']:.4f}\")\n            if not pd.isna(row['AUC-ROC']):\n                print(f\"AUC-ROC: {row['AUC-ROC']:.4f}\")\n        print(f\"Overfitting: {row['Overfit']:.4f}\\n\")\n\n\nGuardar modelos\n\n\ndef save_models(model, model_type='classification'):\n    os.makedirs('models', exist_ok=True)\n\n    if model_type == 'regression':\n        joblib.dump(model, 'models/best_regression_model.pkl')\n    elif model_type == 'classification':\n        joblib.dump(model, 'models/best_classification_model.pkl')\n    elif model_type == 'scaler':\n        joblib.dump(model, 'models/scaler.pkl')",
    "crumbs": [
      "Caso 2: Desempeño estudiantes de matemáticas",
      "Modelos predictivos"
    ]
  },
  {
    "objectID": "case2_modeling.html#separación-de-datos-en-entrenamiento-y-prueba",
    "href": "case2_modeling.html#separación-de-datos-en-entrenamiento-y-prueba",
    "title": "Caso 2: Análisis de Desempeño Estudiantil en Matemáticas",
    "section": "Separación de datos en entrenamiento y prueba",
    "text": "Separación de datos en entrenamiento y prueba\nSepararemos los datos en entrenamoento y prueba con un tamaño de prueba del 20% de forma estratificada para la clasificación.\n\nX_train, X_test, y_train_reg, y_test_reg, y_train_clf, y_test_clf = train_test_split(\n    X, y_reg, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n)\n\nprint(f'Train size: {X_train.shape[0]}')\nprint(f'Test size: {X_test.shape[0]}')\n\nTrain size: 8000\nTest size: 2000\n\n\nVerificamos la distribución de las clases en el conjunto de entrenamiento y prueba para la clasificación.\n\nprint(f'Train distribution: {y_train_clf.sum()} ({y_train_clf.sum()/len(y_train_clf)*100:.1f}%)')\nprint(f'Test distribution: {y_test_clf.sum()} ({y_train_clf.sum()/len(y_train_clf)*100:.1f}%)')\n\nTrain distribution: 1906 (23.8%)\nTest distribution: 476 (23.8%)",
    "crumbs": [
      "Caso 2: Desempeño estudiantes de matemáticas",
      "Modelos predictivos"
    ]
  },
  {
    "objectID": "case2_modeling.html#escalamiento-de-características",
    "href": "case2_modeling.html#escalamiento-de-características",
    "title": "Caso 2: Análisis de Desempeño Estudiantil en Matemáticas",
    "section": "Escalamiento de características",
    "text": "Escalamiento de características\n\nscaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nX_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n\nsave_models(scaler, 'scaler')",
    "crumbs": [
      "Caso 2: Desempeño estudiantes de matemáticas",
      "Modelos predictivos"
    ]
  }
]